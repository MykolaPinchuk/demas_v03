# Speedup Plan (ranked, low-risk first)

1) [Done] Parallelize across tasks (one container per task)
- Impact: High (near-linear speedup up to ~CPU cores)
- Effort/Risk: Low; orchestration only, per-task logic unchanged
- Validation: Run 12 concurrent single-task runs vs sequential; compare wall time
- Notes: Cap at ~12–14 on 16-thread box; keep per-task attempts sequential

2) “Triage then full” test strategy (flag)
- Impact: Medium; big savings on failing attempts
- Effort/Risk: Low; adjust test invocation order only
- Validation: On a failing repo, measure attempt time with and without triage (-q -x first)

3) Pytest xdist available (opt-in per-repo)
- Impact: Medium on large suites; none on tiny suites
- Effort/Risk: Low; preinstall pytest-xdist, but default off for safety
- Validation: Enable -n auto on one heavy repo and confirm speedup; keep default off globally

4) Size-aware scheduling (longest-first)
- Impact: Medium; better CPU utilization, lower tail latency
- Effort/Risk: Low; simple heuristic ordering of tasks
- Validation: Compare makespan random vs longest-first on 7-task set

5) Local git mirrors / cached shallow clones
- Impact: Medium on network-bound clones
- Effort/Risk: Low–Medium; small cache layer, careful invalidation per ref
- Validation: Measure clone time before/after; expect near-instant local copies

6) Heavier base image variant (tools + common build deps preinstalled)
- Impact: Medium–High; reduces per-run build/install variance
- Effort/Risk: Low; add a second Dockerfile tag and switch by flag
- Validation: Compare cold-start of heavy repos on slim vs heavy image

Operational recommendations
- Default profile on 16 threads: 12 parallel tasks; default single-proc tests; triage+full enabled by flag; xdist opt-in per-repo; heavy image available if needed.
- Resource controls: Consider --cpuset-cpus to reduce context switching; memory caps to avoid swap under high parallelism.

Current empirical note (this machine)
- Full 7-task agent suite:
  - Qwen 480B FP8: jobs=12 -> 42.98s; jobs=7 -> 62.60s (jobs=12 faster)
  - GLM-4.5-FP8: jobs=12 -> 41.08s
- Recommendation: for 7 tasks on 16-thread host, start with --jobs 12–14; adjust per workload.

Deferred options – risks and caveats (for later stages)
- Heavier base image
  - Pros: steadier installs, less variance. Cons: large image, longer rebuilds, risk masking missing deps.
- Triage then full (flag)
  - Pros: faster failing attempts. Cons: may miss intermittent/order issues; must ensure full run on pass; keep off for benchmarks.
- Pytest xdist (opt-in per repo)
  - Pros: speedup on large suites. Cons: concurrency can surface nondeterminism; some suites/plugins not xdist-safe; validate before enabling.
- Size-aware scheduling
  - Pros: better utilization, lower tail. Cons: needs rough duration estimates; misestimates can hurt fairness.
- Local git mirrors / cached shallow clones
  - Pros: faster clones, less network. Cons: disk usage and invalidation complexity.
- Persist site-packages/venv on volume
  - Pros: avoids reinstalls across attempts. Cons: high risk of state leakage/version conflicts; requires robust invalidation; use cautiously for multi-attempt loops only.
- Faster installers (uv / no-build-isolation)
  - Pros: faster resolves/builds. Cons: compatibility differences vs pip isolation; test carefully.
- Long-lived container reuse per task
  - Pros: amortize container start/install across attempts. Cons: state leakage across attempts; must enforce strict resets for reproducibility.

